# 環境設定

リポジトリをクローンすると、`sample.env` にサンプルの環境設定があります。シミュレーションで使用するモデル、データベース、並行処理のレベルを設定できます。

### 必須のモデル設定

- API キー
- `LLM_PROVIDER` で API を設定（現在は `"openai"` のみ対応）
- `LLM_MODEL` でモデルを設定（例: `"gpt-4.1"`）

### 任意の追加モデル設定

- `LLM_REASONING_EFFORT` で推論の深さを制御（対応モデルのみ。選択肢: `"minimal"`, `"standard"`, `"high"`）
- `LLM_TEMPERATURE` で応答のランダム性を制御
- `LLM_MAX_TOKENS` で1回の応答あたりの最大トークン数を設定
- `LLM_MAX_CONCURRENCY` でレート制限を防ぐための同時リクエスト数を制限

### データベース設定

`sample.env` にはデータベースのログイン情報を設定するための変数がいくつかあります。デフォルト値の使用を推奨します。追加で以下を設定できます:

- `POSTGRES_MAX_CONNECTIONS` でコネクションプールの同時接続数を制限

## FAQ

- **_レート制限エラーを防ぐにはどうすればよいですか？_**

  `LLM_MAX_CONCURRENCY` を 10 程度に下げてみてください（1 に設定すると、各 LLM 呼び出しが順次実行されます）。

- **_データベース接続数が多すぎるエラーを修正するにはどうすればよいですか？_**

  `POSTGRES_MAX_CONNECTIONS` を減らしてみてください。

- **_同じデータベースでより多くのシミュレーションを並列実行するにはどうすればよいですか？_**

  `POSTGRES_MAX_CONNECTIONS` を減らしてみてください。
